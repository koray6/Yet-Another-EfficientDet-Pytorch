import gc
import memory_profiler as mp
import torch.nn as nn
import numpy as np
import os
import pynvml
import tvm.relay as relay
import threading
import time
import torch
import tvm
import statistics

from tqdm import tqdm


def relay_exe_from_pytorch(model: nn.Module, input_name: str, sample_inputs: torch.Tensor, tvm_target_str:str, vm_output_dir:str, use_scripting:bool=False)->tvm.runtime.vm.Executable:
    """Converts a PyTorch/TorchScript model into a Relay VM executable and saves.

    Args:
        model (nn.Module): PyTorch/TorchScript model to convert.
        input_name (str): Desired input name for Relay VM.
        sample_inputs (torch.Tensor): Dummy inputs to use when tracing the PyTorch model.
        tvm_target_str (str): Compile target string (e.g. "cuda -libs=cudnn")
        vm_output_dir (str): Output directory for VM artifacts.
        use_scripting (bool, optional): Compile the PyTorch model with scripting instead of tracing. Defaults to False.
    Returns:
        tvm.runtime.vm.Executable: Relay VM executable.
    """
    with torch.no_grad():
        model_ts = torch.jit.script(model.eval()).eval() if use_scripting else torch.jit.trace(model.eval(), sample_inputs).eval()
        relay_ir, relay_params = relay.frontend.from_pytorch(model_ts, [(input_name, sample_inputs.shape)])
    with tvm.transform.PassContext(opt_level=3):
        relay_exe = relay.vm.compile(relay_ir, target=tvm_target_str, params=relay_params)

    vm_code, vm_lib = relay_exe.save()
    try:
        os.mkdir(vm_output_dir)
    except:
        pass
    vm_lib.export_library(os.path.join(vm_output_dir, "lib.so"))
    with open(os.path.join(vm_output_dir, "code.ro"), "wb") as vm_code_file:
        vm_code_file.write(vm_code)
    return relay_exe

def start_relay_vm(vm_dir:str, tvm_device:tvm._ffi.runtime_ctypes.Device)->tvm.runtime.vm.VirtualMachine:
    """Spins up a Relay VM from a directory containing VM artifacts.

    Args:
        vm_dir (str): Directory for VM artifacts.
        tvm_device (tvm._ffi.runtime_ctypes.Device): TVM device to run.

    Returns:
        tvm.runtime.vm.VirtualMachine: Generated Relay VM.
    """
    vm_lib = tvm.runtime.load_module(os.path.join(vm_dir, "lib.so"))
    with open(os.path.join(vm_dir, "code.ro"), "rb") as vm_code_file:
        vm_code = bytearray(vm_code_file.read())
    
    relay_exe = tvm.runtime.vm.Executable.load_exec(vm_code, vm_lib)
    relay_vm = tvm.runtime.vm.VirtualMachine(relay_exe, tvm_device)
    return relay_vm

def run_relay_vm(relay_vm: tvm.runtime.vm.VirtualMachine, input:np.ndarray) -> tvm.runtime.ndarray.NDArray:
    """Run Relay VM on input.

    Args:
        relay_vm (tvm.runtime.vm.VirtualMachine): Run this.
        input (np.ndarray): On this.

    Returns:
        tvm.runtime.ndarray.NDArray: Output.
    """
    return relay_vm.run(tvm.nd.array(input))

class VMProfiler:
    def __init__(self, vm_dir:str, target_gpu_idx:int=0) -> None:
        """Profiles a Relay VM model for inference time, memory use, and GPU memory use.

        Garbage collection and `del` is used strategically to clean up memory after use during profiling.

        Args:
            vm_dir (str): Directory containing VM binaries (as generated by vmify.relay_exe_from_pytorch)
            target_gpu_idx (int, optional): GPU index to run the model. If None, run on CPU. Defaults to 0.
        """
        self.vm_dir = vm_dir
        self.target_gpu_idx = target_gpu_idx

    def inference_latency(self, dummy_input:np.array, iters=1000) -> float:
        """Measure model's inference latency (in ms) using a dummy input.

        Args:
            dummy_input (np.array): You know the thing.
            iters (int, optional): Number of iterations to run. Defaults to 1000.

        Returns:
            float: Median latency
        """
        if self.target_gpu_idx is None:
            target_device = tvm.cpu()
        else:
            target_device = tvm.gpu(self.target_gpu_idx)
        print("VMProfiler.inference_latency(): Profiling...")
        all_times = []
        vm = start_relay_vm(self.vm_dir, target_device)
        dummy_input = tvm.nd.array(dummy_input)
        for i in tqdm(range(iters)):
            gc.disable()
            tick = time.time()
            vm.run(tvm.nd.array(dummy_input))
            tock = time.time()
            gc.enable()
            all_times.append((tock-tick)*1000) # report in ms

        del vm
        gc.collect()
        return statistics.median(all_times)


    def memory_utilization(self, dummy_input:np.array, monitor_interval:float=0.1) -> dict:
        """Samples memory use (in MB) at intervals during VM loading and running.

        Args:
            dummy_input (np.array): You know the thing.
            monitor_interval (float, optional): Memory use sampling interval, in seconds. Defaults to 0.1.

        Returns:
            dict: Max memory use in MB. {"Load VM from disk": float, "Run VM inference": float}
        """
        if self.target_gpu_idx is None:
            target_device = tvm.cpu()
        else:
            target_device = tvm.gpu(self.target_gpu_idx)
        print("VMProfiler.memory_utilization(): Profiling memory use...")
        gc.collect()
        starting_mem_usage = mp.memory_usage(interval=monitor_interval, include_children=True, multiprocess=True, max_usage=True)
        max_mem_usage = mp.memory_usage(proc=(start_relay_vm, [self.vm_dir, target_device]), interval=monitor_interval, include_children=True, multiprocess=True, max_usage=True)
        startup_mem = max_mem_usage - starting_mem_usage
        
        vm = start_relay_vm(self.vm_dir, target_device)
        gc.collect()
        starting_mem_usage = mp.memory_usage(interval=monitor_interval, include_children=True, multiprocess=True, max_usage=True)
        max_mem_usage = mp.memory_usage(proc=(run_relay_vm, [vm, dummy_input]), interval=monitor_interval, include_children=True, multiprocess=True, max_usage=True)
        run_mem = max_mem_usage - starting_mem_usage

        del vm
        gc.collect()

        return {"Load VM from disk": startup_mem, "Run VM inference": run_mem}


    def nvidia_gpu_memory_utilization(self, dummy_input:np.array, measure_after_backend_init:bool=False, monitor_interval:float=0.1)->float:
        """Samples NVIDIA GPU memory use (in MB) at intervals during VM inference.

        Args:
            dummy_input (np.array): You know the thing.
            measure_after_backend_init (bool, optional): Set to True to take measurements *after* initializing any backends. Defaults to False.
            monitor_interval (float, optional): Memory use sampling interval, in seconds. Defaults to 0.1.

        Raises:
            ValueError: If target GPU is not set

        Returns:
            float: Maximum GPU memory used by the model, in MB
        """
        if self.target_gpu_idx is None :
            raise ValueError("VMProfiler.profile_gpu_memory_utilization(): self.target_gpu_idx cannot be None")
        pynvml.nvmlInit()

        gpu_handle = pynvml.nvmlDeviceGetHandleByIndex(self.target_gpu_idx)
        tvm_gpu = tvm.gpu(self.target_gpu_idx)
        

        if measure_after_backend_init:
            print("VMProfiler.nvidia_gpu_memory_utilization(): Quietly running a VM first to initialize any NVIDIA backends...")
            starter_vm = start_relay_vm(self.vm_dir, tvm_gpu)
            run_relay_vm(starter_vm, dummy_input)
            del starter_vm
            gc.collect()

        vm = start_relay_vm(self.vm_dir, tvm_gpu)
        print("VMProfiler.nvidia_gpu_memory_utilization(): Profiling GPU memory...")
        starting_gpu_mem_usage = pynvml.nvmlDeviceGetMemoryInfo(gpu_handle).used
        gpu_mem_usages = []
        fn_thread = threading.Thread(target=run_relay_vm, name="profile_this_thread", args=[vm, dummy_input])
        fn_thread.start()
        while fn_thread.is_alive():
            gpu_mem_usage = pynvml.nvmlDeviceGetMemoryInfo(gpu_handle).used
            gpu_mem_usages.append(gpu_mem_usage)
            time.sleep(monitor_interval)
        fn_thread.join() # Just to be 100% sure everything is buttoned up
        ending_gpu_mem_usage = pynvml.nvmlDeviceGetMemoryInfo(gpu_handle).used
        max_gpu_mem_usage = (max(max(gpu_mem_usages), ending_gpu_mem_usage) - starting_gpu_mem_usage) / 1024 / 1024 # Reports MB
        del vm
        gc.collect()
        return max_gpu_mem_usage


    
